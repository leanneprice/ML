{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - If you use _linear regression_ in a classification setting, the predicted y will be a continuous variables and not guaranteed to be between 0 and 1\n",
    " - Since we want to ensure that the predicted y is in between 0 and 1 to represent probability of \"has_covid\", we will use _logistic regression_\n",
    " - Further reading: [Difference between linear regression and logistic classifier](https://www.analyticsvidhya.com/blog/2020/12/beginners-take-how-logistic-regression-is-related-to-linear-regression/#:~:text=The%20Differences%20between%20Linear%20Regression,Logistic%20regression%20provides%20discreet%20output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>lung_capacity</th>\n",
       "      <th>body_temperature</th>\n",
       "      <th>has_covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132.894691</td>\n",
       "      <td>6.931665</td>\n",
       "      <td>39.270112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.128239</td>\n",
       "      <td>6.715135</td>\n",
       "      <td>37.005833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.982006</td>\n",
       "      <td>6.580677</td>\n",
       "      <td>38.079465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112.337762</td>\n",
       "      <td>5.482720</td>\n",
       "      <td>37.662576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.165263</td>\n",
       "      <td>6.664360</td>\n",
       "      <td>36.922810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blood_pressure  lung_capacity  body_temperature  has_covid\n",
       "0      132.894691       6.931665         39.270112          0\n",
       "1      117.128239       6.715135         37.005833          1\n",
       "2      108.982006       6.580677         38.079465          0\n",
       "3      112.337762       5.482720         37.662576          0\n",
       "4      113.165263       6.664360         36.922810          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the COVID dataset.\n",
    "data = pd.read_csv(\"./data/synth_covid.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if there are any NaN values. If so, impute them with the mean of that particular column depending on \n",
    "# if the obseration has covid or not.\n",
    "# Ex: If an observation has a missing value of lung capacity and no COVID, impute the missing value with the mean\n",
    "# of lung_capacity only of those observations that have COVID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chat in class esther\n",
    "# data.loc[data[\"has_covid\"] == 0, \"blood_pressure\"] = data.loc[data[\"has_covid\"] == 0, \"blood_pressure\"].fillna(values_no_covid)\n",
    "# from filipa\n",
    "# data.loc[cond_covid_pos, \"blood_pressure\"] = data.loc[cond_covid_pos, \"blood_pressure\"].fillna(blood_covid_pos_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blood_pressure      3\n",
       "lung_capacity       2\n",
       "body_temperature    4\n",
       "has_covid           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields that have NaN values are numeric, so can calculate mean\n",
    "# if categorical code pick mode as the centrality metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first fill in missing values for blood pressure\n",
    "# Filipa mistakenly thought in class that the NaN values needed to be replaced with average for entire field\n",
    "# i.e., not segregated by covid\n",
    "# but she showed some nice functions so I have repeated here and commented out\n",
    "\n",
    "# SOLUTION 1\n",
    "\n",
    "blood_pressure_mean = data[\"blood_pressure\"].mean()\n",
    "blood_pressure_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that get 0 NaN values\n",
    "# data[\"blood_pressure\"].fillna(blood_pressure_mean).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# happy with sanity check so assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"blood_pressure\"] = data[\"blood_pressure\"].fillna(blood_pressure_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raised that average needs to be conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to build condition\n",
    "\n",
    "cond_covid_pos = data[\"has_covid\"] == 1\n",
    "cond_covid_neg = data[\"has_covid\"] == 0\n",
    "\n",
    "mean_blood_pressure_covid_pos = data[cond_covid_pos][\"blood_pressure\"].mean()\n",
    "mean_blood_pressure_covid_neg = data[cond_covid_neg][\"blood_pressure\"].mean()\n",
    "\n",
    "mean_blood_pressure_covid_pos, mean_blood_pressure_covid_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[cond_covid_pos].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was the example shown in class but it didn't work\n",
    "# warning - try using .loc\n",
    "#data[cond_covid_pos][\"blood_pressure\"] = data[cond_covid_pos][\"blood_pressure\"].fillna(mean_blood_pressure_covid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it didn't make the change, can issues with the data pointing to the same place\n",
    "#data[cond_covid_pos].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta's solution\n",
    "# remember cond_covid_pos = data[\"has_covid\"] == 1\n",
    "#data.loc[cond_covid_pos, \"blood_pressure\"] = data.loc[cond_covid_pos, \"blood_pressure\"].fillna(mean_blood_pressure_covid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION ALL TOGETHER\n",
    "# can create a for loop to do this ...\n",
    "\n",
    "# list of columns want to fill missing values \n",
    "col_list = [\"blood_pressure\", \"lung_capacity\", \"body_temperature\"]\n",
    "\n",
    "# condition pos/neg covid\n",
    "cond_covid_pos = data[\"has_covid\"] == 1\n",
    "cond_covid_neg = data[\"has_covid\"] == 0\n",
    "\n",
    "for col in col_list:\n",
    "    mean_col_covid_pos = data[cond_covid_pos][col].mean()\n",
    "    mean_col_covid_neg = data[cond_covid_neg][col].mean()\n",
    "\n",
    "    data.loc[cond_covid_pos, col] = data.loc[cond_covid_pos, col].fillna(mean_col_covid_pos)\n",
    "    data.loc[cond_covid_neg, col] = data.loc[cond_covid_neg, col].fillna(mean_col_covid_neg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nick's more programtic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop has covid column as want all other columns in loop\n",
    "col_list_2 = data.drop(\"has_covid\", axis=1).columns\n",
    "\n",
    "# blank dict\n",
    "means = {}\n",
    "\n",
    "for col in col_list_2:\n",
    "    # store averages for covid pos/neg and col in dict\n",
    "    means[col] = {\n",
    "        0: np.mean(data[data[\"has_covid\"] == 0][col]),\n",
    "        1: np.mean(data[data[\"has_covid\"] == 1][col])        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 117.87762528505783, 1: 123.07133180423557}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[\"blood_pressure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blood_pressure      3\n",
       "lung_capacity       2\n",
       "body_temperature    4\n",
       "has_covid           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    has_covid = row[\"has_covid\"]\n",
    "    \n",
    "    for col in col_list_2:\n",
    "    # specific value want to change\n",
    "        value = row[col]\n",
    "        if np.isnan(value):\n",
    "            data.loc[index, col] = means[col][int(has_covid)]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blood_pressure      0\n",
       "lung_capacity       0\n",
       "body_temperature    0\n",
       "has_covid           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to drop any NaN values and come back to this if I have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Seaborn, create a histogram of the blood_pressure. Separate this by has_covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data = data,\n",
    "    x = \"blood_pressure\",\n",
    "    hue = \"has_covid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of the column has_covid? In other words, how many patients have COVID and don't have COVID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"has_covid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "636/(636 + 364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Divide the dataset into an 80/20 training and testing split with a random_state of 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"has_covid\"], axis = 1)\n",
    "y = data[\"has_covid\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train/fit a logistic regression model on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class prediction of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class probabilities of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(X_test)\n",
    "y_prob[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "For each of these metrics (Accuracy, Recall, Precision, and F1) and using <i><b>ONLY</b></i> the NumPy library and Pandas, calculate these metrics from scratch. Then, compare this to Scikit-learn's version of these metrics by importing the necessary metric. Are your results similar or different? Why/Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using np and pd to calculate  tp, tn, fp and fn\n",
    "tp = np.sum(np.logical_and(y_pred == 1, y_test == 1))\n",
    "tn = np.sum(np.logical_and(y_pred == 0, y_test == 0))\n",
    "fp = np.sum(np.logical_and(y_pred == 1, y_test == 0))\n",
    "fn = np.sum(np.logical_and(y_pred == 0, y_test == 1))\n",
    "print(\"tp \", tp, \"; tn \", tn, \"; fp \", fp, \"; fn \", fn, \"; sum \", (tp + tn + fp + fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using np and pd \n",
    "my_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"my_accuracy \", my_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn \n",
    "from sklearn.metrics import accuracy_score\n",
    "sklearn_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"sklearn_accuracy \", sklearn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "$$Recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recall = tp / (tp + fn)\n",
    "print(\"my_recall \", my_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "sklearn_recall = recall_score(y_test, y_pred)\n",
    "print(\"sklearn_recall \", sklearn_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "$$Precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_precision = tp / (tp + fp)\n",
    "print(\"my_precision \", my_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "sklearn_precision = precision_score(y_test, y_pred)\n",
    "print(\"sklearn_precision \", sklearn_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "$$F1= 2 * \\frac{\\large{precision * recall}}{\\large{precision + recall}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_f1 = 2 * ((my_precision * my_recall) / (my_precision + my_recall))\n",
    "print(\"my_f1 \", my_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "sklearn_f1 = f1_score(y_test, y_pred)\n",
    "print(\"sklearn_f1 \", sklearn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. When testing patients for COVID-19, it is extremely important to capture as many positive cases as possible to understand the prevalence of the virus within a given area. It is very dangerous to misdiagnose someone as not having the virus when in fact they do because they can spread the disease to others without knowing. On the other hand, however, if someone is healthy but diagnosed as having the virus the penalty is they will unnecessarily self-isolate for a few days, which is inconvenient but not as harmful. If this were the case, which metric would you want to maximize? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be considered preferable to favour FN as this is dangerous to others, which would favour recall. However, the consequence of FP cannot be disregarded so you may argue that and F1 could be a better measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let's say that we're running a zombie task force and our job is to eliminate all zombies via flamethrower (because why not). If zombies are within the general population, let's say that these zombies are able to live freely without infecting anyone else however. We go to a brand new city to do our job and will examine every citizen to check if they are a zombie or not. Because we do not want to put an actual human through this tortorous event and would rather have the zombie live among humans, which metric would be best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimise FP so favour precision as a metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Could you give an example of when accuracy might not be the best metric to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there was skew in the outcome such in this case where approximately 64% of the sample population do not have covid, so our accuracy is not much better than guessing that a participant doesn't have covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
